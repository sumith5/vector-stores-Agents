{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Combine agents and vector stores\n",
        "This notebook covers how to combine agents and vector stores. The use case for this is that you've ingested your data into a vector store and want to interact with it in an agentic manner.\n",
        "\n",
        "The recommended method for doing so is to create a RetrievalQA and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set return_direct=True to really just use the agent as a router."
      ],
      "metadata": {
        "id": "a7HVLWZversW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SO6jdrQaemHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai chromadb langchain-community"
      ],
      "metadata": {
        "id": "cK-dTL4ZJ5Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai"
      ],
      "metadata": {
        "id": "fYMHvAxNKRJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "id": "zgjs_m5WT7iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcUiJ-vHJ3m0"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b4s_tF3mK250"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_path = \"\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "j6rlyhRGLhF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(doc_path)\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=\"sk-proj-c7BfnwNqZu4r43n9qCwKT3BlbkFJYvmLjhtpOtaxpJ95KMSN\")\n",
        "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"1\")"
      ],
      "metadata": {
        "id": "eRHmSwALLsjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waterline = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "MXiQCAYbNe-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "doc_path2= \"\"\n",
        "loader2 = TextLoader(doc_path2)\n",
        "documents2 = loader2.load()\n",
        "text_splitter2 = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts2 = text_splitter2.split_documents(documents2)\n",
        "\n",
        "embeddings2 = OpenAIEmbeddings(openai_api_key=\"sk-proj-c7BfnwNqZu4r43n9qCwKT3BlbkFJYvmLjhtpOtaxpJ95KMSN\")\n",
        "docsearch2 = Chroma.from_documents(texts2, embeddings2, collection_name=\"line2\")"
      ],
      "metadata": {
        "id": "pVy0uFG1Nx07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waterline2 = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=docsearch2.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "7CnyvDViO5Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import things that are needed generically\n",
        "from langchain.agents import AgentType, Tool, initialize_agent\n",
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "iUY1LDYZOrKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"A QA system\",\n",
        "        func=1.run,\n",
        "        description=\"useful for when you need to answer questions about the A.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"QA System\",\n",
        "        func=2.run,\n",
        "        description=\"useful for when you need to answer questions about the B\",\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "IPjY_xU8OvFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "l1cP9x_qPe-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"\"\n",
        ")"
      ],
      "metadata": {
        "id": "RrPxcp3NPkwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"\"\n",
        ")"
      ],
      "metadata": {
        "id": "l_NDJFzxPuxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SvuS1HpddKWT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}